{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##We should start by loading any packages we will need, as well as any data.\n",
    "\n",
    "## We can import a full package, but I'm just goign to import some:\n",
    "\n",
    "## sklearn things we need:\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# numpy and friends\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "## We don't need all of this, but it's good to get anything I need in the very first block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X values are a 64 digit string: [ 0.  0.  4. 10. 16. 16.  7.  0.  0.  3. 16. 13. 11. 16.  2.  0.  0.  1.\n",
      "  3.  0. 10.  9.  0.  0.  0.  0.  5.  8. 14. 15. 13.  0.  0.  0. 15. 16.\n",
      " 14. 12.  8.  0.  0.  0.  3. 12.  7.  0.  0.  0.  0.  0.  0. 15.  4.  0.\n",
      "  0.  0.  0.  0.  3. 14.  1.  0.  0.  0.]\n",
      "and the y is the value of the number 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lets's start with the handwritten numbers that we've seen a lot of:\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits['data']   # this is the data with each 8x8 image \"flattened\" into a length-64 vector.\n",
    "Y = digits['target'] # these are the labels (0-9). \n",
    "\n",
    "## Let's look at one number:\n",
    "## I've chosen randomly, but set n to any number under 1000\n",
    "\n",
    "\n",
    "n = 653\n",
    "\n",
    "plt.imshow(digits['images'][n], cmap='Greys_r')\n",
    "plt.title('This is a %d' % digits['target'][n])\n",
    "\n",
    "print(\"The X values are a 64 digit string:\", X[n])\n",
    "print(\"and the y is the value of the number\", Y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The first step is to break the data into the training set, and the test set.  \n",
    "## Luckily, sklearn has you covered:\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "## test_size tells the algrithm that we want to reserve 20% for the test (or validation) set.  Try it!  \n",
    "## Now redo it with a test set at 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Questions\n",
    "\n",
    "1. How big is the full data set? How many numbers in training set?  How many are held back in the test set?  You should have 30% in your test set.\n",
    "2. What is the L1 distance between `X[15]` and `X[25]`?  (Manhattan)\n",
    "3. What is the L2 distance between `X[15]` and `X[25]`?  (Euclidean)\n",
    "4. What is the L3 distance between `X[15]` and `X[25]`?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `KNeighborsClassifier` not found.\n"
     ]
    }
   ],
   "source": [
    "## Lets do it!\n",
    "\n",
    "\n",
    "## Run this to learn about the function:\n",
    "?KNeighborsClassifier\n",
    "\n",
    "## FYI: Minkowski distance means the Lp norm, so we can set p = 2 for Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error was:  0.016701461377870562\n",
      "The testing error was:  0.025\n"
     ]
    }
   ],
   "source": [
    "## For now, I'm going to set K = 3, and use the Euclidean or L2 norm.  \n",
    "\n",
    "#Pick a name for your model -> I'm going to use a random word: cupcake\n",
    "\n",
    "#step 1: let python know what algorithm I'm using:\n",
    "cupcake =neighbors.KNeighborsClassifier(n_neighbors=15, p =2 )\n",
    "#step 2: Train the model on ONLY THE TRAINING DATA (fit!)\n",
    "cupcake.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "##Now we have a well trained model!  But is it a good model?\n",
    "## I'm going to look at the errors in BOTH my training and test sets.  \n",
    "## We do this by predicting what Y will be for each set, than actually comparing\n",
    "\n",
    "Y_pred_train = cupcake.predict(X_train) \n",
    "Y_pred = cupcake.predict(X_test)\n",
    "\n",
    "##record errors\n",
    "error_train=list(Y_train == Y_pred_train).count(False)/len(Y_train)\n",
    "error_test=list(Y_test == Y_pred).count(False)/len(Y_test)\n",
    "\n",
    "##Look it over:\n",
    "print(\"The training error was: \", error_train)\n",
    "print(\"The testing error was: \", error_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn:\n",
    "\n",
    "For this week, we are going to turn a blind eye to the fact that we are experimenting on the test data.  Try out different models!  Look at different $K$ values, and different $p$ values to see if you can find something that works better than others.  Can you automate this process using some loops or other tools?\n",
    "\n",
    "Explain your best model, and hand it in.  Expect that random change may affect different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
